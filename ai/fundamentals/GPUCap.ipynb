{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test GPU Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.0.1\n",
      "fp16 available: True\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# get pytorch version\n",
    "version = torch.__version__\n",
    "print(\"Pytorch version: {}\".format(version))\n",
    "# check fp16 availability\n",
    "fp16_available = torch.backends.cudnn.enabled\n",
    "print(\"fp16 available: {}\".format(fp16_available))\n",
    "# check if GPU is available\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(\"GPU available: {}\".format(gpu_available))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'torch' has no attribute 'fp8'\n",
      "torch.int8\n",
      "tensor([1, 2, 3], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    t = torch.tensor([1,2,3], dtype=torch.fp8)\n",
    "    print(t.dtype)\n",
    "    print(t)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "t = torch.tensor([1,2,3], dtype=torch.int8)\n",
    "print(t.dtype)\n",
    "print(t)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Float16 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2947], device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Epoch: 0, Loss: 8.66406\n",
      "Epoch: 10, Loss: 3.67188\n",
      "Epoch: 20, Loss: 4.82422\n",
      "Epoch: 30, Loss: 6.45312\n",
      "Epoch: 40, Loss: 3.03711\n",
      "Epoch: 50, Loss: 3.86719\n",
      "Epoch: 60, Loss: 2.49609\n",
      "Epoch: 70, Loss: 3.06055\n",
      "Epoch: 80, Loss: 2.29492\n",
      "Epoch: 90, Loss: 3.44336\n",
      "Epoch: 100, Loss: 0.85889\n",
      "Epoch: 110, Loss: 2.58984\n",
      "Epoch: 120, Loss: 1.19043\n",
      "Epoch: 130, Loss: 0.81494\n",
      "Epoch: 140, Loss: 0.78564\n",
      "Epoch: 150, Loss: 0.33667\n",
      "Epoch: 160, Loss: 0.55273\n",
      "Epoch: 170, Loss: 0.39258\n",
      "Epoch: 180, Loss: 0.37085\n",
      "Epoch: 190, Loss: 0.10693\n",
      "Epoch: 200, Loss: 0.13696\n",
      "Epoch: 210, Loss: 0.05936\n",
      "Epoch: 220, Loss: 0.04858\n",
      "Epoch: 230, Loss: 0.02237\n",
      "Epoch: 240, Loss: 0.01358\n",
      "Epoch: 250, Loss: 0.02466\n",
      "Epoch: 260, Loss: 0.01848\n",
      "Epoch: 270, Loss: 0.00971\n",
      "Epoch: 280, Loss: 0.00508\n",
      "Epoch: 290, Loss: 0.00134\n",
      "Epoch: 300, Loss: 0.00487\n",
      "Epoch: 310, Loss: 0.00275\n",
      "Epoch: 320, Loss: 0.00037\n",
      "Epoch: 330, Loss: 0.00096\n",
      "Epoch: 340, Loss: 0.00061\n",
      "Epoch: 350, Loss: 0.00085\n",
      "Epoch: 360, Loss: 0.00022\n",
      "Epoch: 370, Loss: 0.00058\n",
      "Epoch: 380, Loss: 0.00027\n",
      "Epoch: 390, Loss: 0.00082\n",
      "Epoch: 400, Loss: 0.00036\n",
      "Epoch: 410, Loss: 0.00044\n",
      "Epoch: 420, Loss: 0.00028\n",
      "Epoch: 430, Loss: 0.00033\n",
      "Epoch: 440, Loss: 0.00055\n",
      "Epoch: 450, Loss: 0.00015\n",
      "Epoch: 460, Loss: 0.00028\n",
      "Epoch: 470, Loss: 0.00030\n",
      "Epoch: 480, Loss: 0.00060\n",
      "Epoch: 490, Loss: 0.00027\n",
      "Epoch: 500, Loss: 0.00018\n",
      "Epoch: 510, Loss: 0.00027\n",
      "Epoch: 520, Loss: 0.00053\n",
      "Epoch: 530, Loss: 0.00037\n",
      "Epoch: 540, Loss: 0.00037\n",
      "Epoch: 550, Loss: 0.00033\n",
      "Epoch: 560, Loss: 0.00023\n",
      "Epoch: 570, Loss: 0.00042\n",
      "Epoch: 580, Loss: 0.00011\n",
      "Epoch: 590, Loss: 0.00038\n",
      "Epoch: 600, Loss: 0.00019\n",
      "Epoch: 610, Loss: 0.00020\n",
      "Epoch: 620, Loss: 0.00017\n",
      "Epoch: 630, Loss: 0.00040\n",
      "Epoch: 640, Loss: 0.00019\n",
      "Epoch: 650, Loss: 0.00021\n",
      "Epoch: 660, Loss: 0.00019\n",
      "Epoch: 670, Loss: 0.00012\n",
      "Epoch: 680, Loss: 0.00012\n",
      "Epoch: 690, Loss: 0.00042\n",
      "Epoch: 700, Loss: 0.00026\n",
      "Epoch: 710, Loss: 0.00024\n",
      "Epoch: 720, Loss: 0.00032\n",
      "Epoch: 730, Loss: 0.00015\n",
      "Epoch: 740, Loss: 0.00020\n",
      "Epoch: 750, Loss: 0.00021\n",
      "Epoch: 760, Loss: 0.00017\n",
      "Epoch: 770, Loss: 0.00012\n",
      "Epoch: 780, Loss: 0.00010\n",
      "Epoch: 790, Loss: 0.00026\n",
      "Epoch: 800, Loss: 0.00020\n",
      "Epoch: 810, Loss: 0.00013\n",
      "Epoch: 820, Loss: 0.00014\n",
      "Epoch: 830, Loss: 0.00020\n",
      "Epoch: 840, Loss: 0.00021\n",
      "Epoch: 850, Loss: 0.00013\n",
      "Epoch: 860, Loss: 0.00011\n",
      "Epoch: 870, Loss: 0.00015\n",
      "Epoch: 880, Loss: 0.00005\n",
      "Epoch: 890, Loss: 0.00009\n",
      "Epoch: 900, Loss: 0.00024\n",
      "Epoch: 910, Loss: 0.00005\n",
      "Epoch: 920, Loss: 0.00011\n",
      "Epoch: 930, Loss: 0.00013\n",
      "Epoch: 940, Loss: 0.00021\n",
      "Epoch: 950, Loss: 0.00014\n",
      "Epoch: 960, Loss: 0.00011\n",
      "Epoch: 970, Loss: 0.00017\n",
      "Epoch: 980, Loss: 0.00032\n",
      "Epoch: 990, Loss: 0.00007\n",
      "Epoch: 999, Loss: 0.00010\n",
      "Parameter containing:\n",
      "tensor([[0.9961, 0.9966, 0.9971, 0.9961, 1.0000, 0.9966, 0.9951, 0.9946, 0.9966,\n",
      "         0.9976]], device='cuda:0', dtype=torch.float16, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a model with 2 layers\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        #self.fc1 = nn.Linear(10, 10)\n",
    "        self.fc2 = nn.Linear(10, 1,dtype=torch.float16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = torch.randn(10,dtype=torch.float16)\n",
    "# evaluate the model\n",
    "model = Model()\n",
    "model.eval()\n",
    "model.to(device)\n",
    "x = x.to(device)\n",
    "y = model(x)\n",
    "print(y)\n",
    "\n",
    "\n",
    "\n",
    "# train with this model on GPU with 10 inputs and output should learn to be sum of inputs\n",
    "\n",
    "epochs = 1000\n",
    "lr = 0.01\n",
    "batch_size = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criteria = nn.MSELoss()\n",
    "for i in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    x = torch.randn(batch_size,10,dtype=torch.float16).to(device)\n",
    "    y = model(x)\n",
    "    y_true = x.sum(dim=1, keepdim=True)\n",
    "    loss = criteria(y, y_true)    \n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    loss_val = loss.item()\n",
    "    if i % 10 == 0: \n",
    "        print(f\"Epoch: {i}, Loss: {loss_val:.5f}\")\n",
    "    #print(\"y: {}, x.sum(): {}\".format(y.detach().cpu().item(), x.sum().detach().cpu().item()))\n",
    "print(f\"Epoch: {i}, Loss: {loss_val:.5f}\")\n",
    "print(model.fc2.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
