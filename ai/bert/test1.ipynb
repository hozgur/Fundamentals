{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elon musk\n"
     ]
    }
   ],
   "source": [
    "question = \"Who founded SpaceX?\"\n",
    "context = \"SpaceX was founded in 2002 by entrepreneur Elon Musk.\"\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "\n",
    "start_pos = torch.argmax(outputs.start_logits)\n",
    "end_pos = torch.argmax(outputs.end_logits)\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_pos:end_pos+1]))\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer_tr = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "model_tr = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.9491,  0.5035,  0.4350,  ...,  0.1617, -1.5901, -0.1612],\n",
      "         [-0.2609,  1.6011, -0.4556,  ...,  0.5303, -0.3626,  0.8528],\n",
      "         [-0.4297,  1.4636,  0.1273,  ..., -0.0413, -0.9804,  0.7854],\n",
      "         ...,\n",
      "         [-1.0861, -0.7674, -0.8730,  ..., -0.0669, -0.1636,  0.7165],\n",
      "         [-0.5120,  1.0818, -0.2086,  ...,  0.7050, -1.1560, -0.3437],\n",
      "         [-0.0049, -0.2336, -1.1646,  ...,  0.4064, -0.4265,  0.2740]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.3128, -0.4599,  0.4749, -0.5893, -0.9999,  0.3771, -0.9970,  0.9993,\n",
      "         -0.9318,  0.9461,  0.2453, -0.5353, -0.0228,  0.4793, -0.7184,  0.3799,\n",
      "          0.1856,  0.5947, -0.9962, -0.9788,  0.0767,  0.5780, -0.9978,  0.4876,\n",
      "          0.6861, -0.8772, -0.9948,  0.3983, -0.9930,  0.9999,  0.9998, -0.5311,\n",
      "         -1.0000,  0.9977, -0.3975, -0.9953,  0.9995, -0.6761, -0.3974, -0.9647,\n",
      "         -0.9977, -0.5511, -0.9864, -0.9999, -0.9997, -0.3873, -0.5903,  0.4647,\n",
      "         -0.9742, -0.9000,  0.9993, -0.9507,  0.3077, -0.9612, -0.2844,  0.4112,\n",
      "         -0.9960, -0.5732,  0.4773,  0.2158,  0.9878,  0.9998, -0.9999,  0.6226,\n",
      "         -0.2851, -0.3777, -0.9991, -0.2559,  0.5729, -0.9999,  0.9948,  0.5683,\n",
      "          0.3750, -0.9994, -0.9991,  0.2386,  0.8120, -0.3000, -0.1213,  0.9989,\n",
      "         -1.0000, -0.1361,  0.3238, -0.0279,  0.9962,  0.6680,  1.0000, -0.0312,\n",
      "          0.9982,  0.8572, -0.9994, -0.3082,  0.1340,  0.5176, -0.4138, -0.0429,\n",
      "         -0.9999,  0.9990, -0.3288,  0.9942,  0.9152,  0.9995, -0.4965, -0.7177,\n",
      "          1.0000, -0.5783,  0.9998,  0.5919, -0.9997, -0.9970,  0.2460,  0.2918,\n",
      "         -0.9997,  0.4131, -0.1029, -0.3811,  0.4867, -1.0000, -0.4227,  0.1438,\n",
      "         -1.0000,  1.0000,  0.1091, -0.5066,  1.0000,  0.6449, -0.0663, -0.8488,\n",
      "         -0.0915, -0.9832, -0.2660, -0.9998,  0.1556,  0.9952,  0.1176, -0.1112,\n",
      "         -0.0903,  1.0000,  0.9908, -0.9692, -0.1848,  0.2379,  1.0000,  0.9999,\n",
      "         -1.0000, -0.9993,  0.9814, -0.8709, -0.0891,  1.0000,  0.9718, -0.9997,\n",
      "         -0.3430,  0.9716, -0.9985,  0.9998,  0.0933, -0.0597,  0.9990, -1.0000,\n",
      "         -0.1279, -0.2179,  0.9996, -0.9047, -0.9999,  0.9640, -0.3498, -0.4186,\n",
      "         -0.9871, -0.9997, -1.0000, -0.9998, -1.0000,  0.4011,  0.9990, -0.5526,\n",
      "          0.9285, -1.0000,  0.9997,  1.0000, -0.9193,  0.3195, -0.3115,  0.9913,\n",
      "         -0.9992,  0.9982, -0.1435, -0.9044, -0.4385,  0.2998,  0.1177,  0.9765,\n",
      "         -0.9998, -0.3921,  0.9997,  0.4068,  0.9376, -0.9794, -0.8173,  0.5089,\n",
      "         -0.9991,  0.9988,  1.0000, -0.9984, -0.9982, -0.4154, -0.9997,  0.9891,\n",
      "          0.9592, -0.0946,  0.9120, -0.9998, -0.3993,  0.9976, -0.2121, -0.9972,\n",
      "          0.1077, -0.6951, -0.9972, -0.9991,  0.9992, -0.0255, -0.4338, -0.8676,\n",
      "          0.9991,  0.1981, -0.1841,  0.4376, -0.8359, -0.2593, -0.9997, -0.9994,\n",
      "         -0.9999, -0.4093,  0.9907, -0.9985,  0.9865, -0.4177, -0.9982,  0.9925,\n",
      "          1.0000,  1.0000,  0.3855,  0.9999,  0.3791,  0.1980, -0.9980,  0.2133,\n",
      "          0.0605,  0.3992,  0.4477,  0.8232,  0.6205, -0.9989, -0.9016,  0.0411,\n",
      "         -0.9080, -0.9963,  0.9743,  0.9999, -0.9999, -0.9952,  0.4461,  0.2022,\n",
      "          0.9998,  0.9916,  0.6573, -0.2378, -1.0000,  0.7047, -1.0000,  0.6584,\n",
      "         -0.5392,  0.9938,  0.9999, -0.7099, -0.9990,  0.3114, -1.0000, -0.9996,\n",
      "          0.4401, -0.3861,  0.2239,  0.9994,  0.9559,  0.9996,  0.3644,  0.9968,\n",
      "          0.9999, -0.1203,  0.9947,  0.9986, -0.9999, -0.9999,  0.4171, -0.0598,\n",
      "          0.3673,  0.5407,  0.3999, -0.4166, -0.5812, -0.9995,  0.9948,  0.9717,\n",
      "          1.0000,  0.4344,  0.9963, -1.0000, -0.1714, -0.9950, -0.9998,  0.2763,\n",
      "          0.3829, -0.3244, -0.9994,  0.0772, -0.9964, -0.9944,  0.9999,  0.9985,\n",
      "         -0.9999,  0.5232, -0.1860, -0.9998,  0.9994, -0.9069, -0.0839,  0.9009,\n",
      "         -0.9927, -0.9999,  0.9918,  0.9998,  0.9999, -0.9369, -1.0000, -0.5513,\n",
      "         -0.9937,  0.2730,  0.9561, -1.0000, -0.0696,  0.6835,  0.0904, -0.9944,\n",
      "         -0.9998,  0.0179, -0.9792, -0.5525, -0.5098, -0.1558, -0.3972, -0.0179,\n",
      "          0.9959, -1.0000,  0.9241,  0.9984,  0.9998, -0.4431, -0.4521,  0.4915,\n",
      "         -0.9999, -0.4774,  1.0000,  0.1448, -0.4085,  0.9903,  0.5205, -0.9999,\n",
      "         -0.7829,  0.6582, -0.4649,  0.4231, -0.4399, -0.9930, -0.9998, -0.9989,\n",
      "         -0.9860, -0.1130,  0.9981, -0.9999,  0.7993, -0.1784, -1.0000,  0.4420,\n",
      "         -0.9998,  0.9994,  0.9981,  0.9391,  0.4768, -1.0000, -0.1562,  1.0000,\n",
      "          0.3079,  0.1949,  0.2056,  0.4934, -0.9976, -0.4269, -0.9826, -0.0255,\n",
      "          0.8010,  0.1629,  0.3098,  0.9971,  1.0000,  0.2744, -1.0000,  0.9705,\n",
      "          0.9849,  0.9972, -0.0619, -0.9999, -0.9994,  0.9993,  0.2921,  0.0323,\n",
      "         -0.2631, -1.0000, -0.9618,  1.0000, -0.5154, -0.4131, -0.0029,  0.0624,\n",
      "         -0.0053,  0.9999, -0.0234, -0.1932, -0.5896, -0.9735,  0.5074, -0.9996,\n",
      "          0.9999, -0.9998, -0.0130, -0.1929,  0.9804,  0.4639, -0.6956, -0.5336,\n",
      "         -0.9790, -0.5669,  0.2738,  0.3786, -0.4313,  0.9997,  0.9840,  0.9968,\n",
      "          0.6714,  0.9795, -0.9963,  0.9997, -0.4848, -0.0820,  0.1843, -0.9988,\n",
      "          0.0873, -0.3937, -0.6617,  0.8675, -1.0000,  0.6297,  0.5955, -0.4560,\n",
      "          0.9939, -0.9998, -0.5654,  0.5857, -0.9651, -0.1512,  0.8483, -0.2432,\n",
      "          0.4675,  0.9999, -0.9877,  0.3879, -0.9991, -0.1606,  0.2668,  0.5580,\n",
      "         -0.9844,  0.2206,  0.9943, -0.0917, -0.8182, -0.9986,  0.9998,  0.9998,\n",
      "         -0.1380,  0.3343,  0.7890, -0.9986, -0.2101, -0.2179,  0.9982, -0.9995,\n",
      "          0.4990, -0.6234, -0.1715,  0.2364,  0.5706, -0.4189,  0.1311, -0.2063,\n",
      "          0.9904, -1.0000, -0.9999,  0.5198, -0.6515, -0.9996,  0.9149, -0.9946,\n",
      "         -0.5069,  0.9955,  0.9616,  0.3932, -0.3863, -0.3448, -0.0740, -0.9992,\n",
      "          0.2779, -0.6092,  0.9981, -0.9996, -0.6942,  0.9831, -0.9997, -0.9988,\n",
      "         -0.6256,  0.6159, -0.1219, -0.9945,  0.9999, -0.9953,  0.2449, -0.9983,\n",
      "          0.3257,  1.0000, -0.9990, -0.7132, -0.9990, -0.0081, -1.0000,  0.3420,\n",
      "         -0.7302,  0.9999, -0.1562, -0.9999, -0.3531,  1.0000,  0.9998,  0.9995,\n",
      "          0.8430,  0.1646, -0.2191,  0.2992, -0.9997,  0.3008, -0.9956, -0.9983,\n",
      "          0.9967,  0.3100,  0.9988, -0.9998,  0.6914,  0.9821, -0.2553, -1.0000,\n",
      "          0.9983,  0.9973,  0.4434,  0.7155,  0.6871, -0.9817,  0.2730, -0.1190,\n",
      "          0.5622,  0.9999, -0.1868, -0.9845, -0.1183, -0.9996, -1.0000, -0.9914,\n",
      "          0.6730,  0.3691,  0.9999,  0.9784, -0.2039,  0.9992,  0.0924, -0.1015,\n",
      "          0.0065,  0.9998,  0.1670,  1.0000, -0.4091,  0.3235,  0.9993, -0.9998,\n",
      "          0.6731, -0.5886,  0.1767, -0.9990,  0.2179, -0.0513,  0.9991, -0.1613,\n",
      "         -0.9911, -1.0000,  0.9570, -0.0663, -0.4580,  0.0157,  0.2508, -0.9322,\n",
      "          0.5513, -0.6338, -0.9988,  0.0411, -0.0560, -0.9996, -0.1537,  0.0713,\n",
      "         -0.4195,  0.2197, -0.7387, -0.9986, -0.4488,  0.6513,  0.1733,  0.9397,\n",
      "         -0.3748,  0.9711,  0.9121,  0.9998, -0.1798,  0.0577,  0.6908, -0.9980,\n",
      "          0.5245, -0.0844, -0.9897, -0.9999, -0.5977, -0.9992, -0.7667, -1.0000,\n",
      "         -0.2177,  0.5688, -0.1000,  0.1635, -0.4259,  0.9987, -0.5102, -0.4175,\n",
      "          0.1349,  1.0000,  1.0000,  0.2057, -0.4459,  1.0000,  0.5806,  0.9995,\n",
      "         -0.9998,  0.1784,  0.5316, -0.9980, -0.2266, -0.9988,  0.9874,  0.0217,\n",
      "         -1.0000,  0.9997, -0.9995, -0.2657, -0.9918, -0.1753, -0.9676,  0.1025,\n",
      "         -0.9939,  0.2962,  0.9988, -0.3999,  0.9999, -0.9969, -0.3757, -0.9991,\n",
      "         -0.0241, -0.3235, -0.4373, -0.3181, -0.9999,  0.1755, -0.9998,  0.8465,\n",
      "          1.0000, -0.9668,  0.9971,  0.2947, -0.9998, -0.5690,  1.0000,  0.5423,\n",
      "         -0.6746,  0.9994,  0.3222, -0.3749,  0.3056,  0.3292,  0.0287, -0.3892,\n",
      "          0.3112, -0.6315, -0.9988, -0.5198,  0.2314,  0.9960, -0.9940, -0.3679,\n",
      "          0.2209, -0.9998,  0.9991, -0.3483, -0.4476, -0.0301, -1.0000, -1.0000,\n",
      "          0.9999,  0.1437,  0.9984,  0.9156, -0.4887, -0.4872,  0.9993, -0.6129,\n",
      "          1.0000, -0.9748, -0.4780,  0.4630,  0.9977, -0.9792,  0.9983,  0.9999,\n",
      "         -0.8826,  1.0000, -0.6625,  0.9920, -0.4547, -0.1575,  0.7297, -0.7203,\n",
      "          0.4659, -0.9972, -0.7142, -0.6528, -0.4160, -0.5434, -0.4718,  0.5048,\n",
      "         -0.4213, -0.9058,  1.0000,  0.4560, -0.2409,  1.0000,  0.3596, -1.0000]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Türkiye Cumhuriyetini kim Kurdu?\"\n",
    "context = \"Türkiye Cumhuriyeti, 29 Ekim 1923'te ilan edilmiştir. Cumhuriyetin kurucusu Mustafa Kemal Atatürk'tür.\"\n",
    "\n",
    "inputs = tokenizer_tr(question, context, return_tensors='pt')\n",
    "outputs = model_tr(**inputs)\n",
    "answer = tokenizer_tr.convert_tokens_to_string(tokenizer_tr.convert_ids_to_tokens(inputs['input_ids'][0][start_pos:end_pos+1]))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.008898240514099598,\n",
       " 'start': 0,\n",
       " 'end': 36,\n",
       " 'answer': \"Türkiye Cumhuriyeti, 29 Ekim 1923'te\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=\"dbmdz/bert-base-turkish-cased\")\n",
    "question_answerer(question=question, context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
